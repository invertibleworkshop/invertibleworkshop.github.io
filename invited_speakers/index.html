<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="author" content="Dustin Tran, edited by Chris Cremer & Chin-Wei Huang">
  <link rel="shortcut icon" href="../img/favicon.ico" type="image/x-icon">
  <title>Invertible Neural Nets and Normalizing Flows - Call for Papers</title>

  <!-- CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css">
  <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="../css/main.css">

  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->


</head>





<body>
  <div class="container">

    <div class="row" style="padding:20px">

      <div class="col-xs-3 col-sm-3 col-md-3">
        <img src="../img/innf_logo.gif" style="height:90px" hspace="40" vspace="30" >
      </div>

      <div class="col-xs-12 col-sm-12 col-md-9">
        <div class="row" style="margin-bottom:-10px;">
          <h1 align="center"> INNF+ 2021 </h1>
          <h3 align="center"> ICML Workshop on Invertible Neural Networks, Normalizing Flows, and Explicit Likelihood Models</h3>
          <hr>
          <!-- <br> -->
          <!-- <br> -->
          <!--           <p class="lead">
            December 2, 2018<br>
            <a href="https://goo.gl/maps/GZ2CkVfpFhL2">Le 1000 Conference Center</a><br>
            <a href="https://goo.gl/maps/GZ2CkVfpFhL2">1000 Rue de la Gauchetière Ouest</a><br>
            <a href="https://goo.gl/maps/GZ2CkVfpFhL2">Montréal, QC H3B 0A2, Canada</a><br>
          </p> -->
        </div>
      </div>





      <div class="col-xs-12 col-sm-3 col-md-3" id="sidebar" role="navigation" style="margin-top:-30px;">
        <hr>

        <ul class="nav nav-pills nav-stacked">
          <li><a href="../index.html">Home</a></li>
          <li><a href="../schedule/index.html">Schedule</a></li>
          <li><a href="../call/index.html">Call for Papers</a></li>
<!--          <li><a href="../reviewer_instructions/index.html">Reviewer Instructions</a></li>-->
          <li><a href="../author_instructions/index.html">Author Instructions</a></li>
          <li><a href="../how_it_works/index.html">How It Works</a></li>
          <li><a href="../accepted_papers/index.html">Accepted Papers</a></li>
          <li><a href="../invited_speakers/index.html">Invited Speakers</a></li>
        </ul>

        <hr>

        <ul class="nav temp">
          <li style="padding:0px 15px 5px;">Organizers</li>
          <li><a href="https://chinweihuang.com/">Chin-Wei Huang</a></li>
          <li><a href="https://mila.quebec/en/person/david-scott-krueger/">David Krueger</a></li>
          <li><a href="https://research.google/people/RiannevandenBerg/">Rianne van den Berg</a></li>
          <li><a href="https://gpapamak.github.io/">George Papamakarios</a></li>
          <li><a href="http://rtqichen.com">Ricky Chen</a></li>
          <li><a href="https://danilorezende.com/">Danilo Rezende</a></li>
        </ul>

        <hr>
      </div>






      <div class="col-xs-12 col-sm-9 col-md-9">
<!--        <hr>-->
        <div class="row">
<!--          <br>-->


          <h3>Invited Speakers</h3>



<!-- template
            <h3><a href="[URL]">[NAME]</a> </h3>
            <h4>[TITLE]</h4>
            [ABSTRACT]
            <br>
            <br>
            <strong>Bio:</strong>
            [BIO]
            <br>
            <hr>
-->
          <div class = "post-content">
          <table class="invited" style="margin-bottom:0px; border-top: 0px;">
            <tr>
              <td style="vertical-align:middle">
                <div class="col-xs-12">
                    <p align="center">
                    <img class="people-pic" src="../assets/img/invited/charline.jpg" target="_blank">
                    </p>
                </div>
                <div class="people-name text-center">
                    <a href="http://csml.stats.ox.ac.uk/people/lelan/" target="_blank">Charline Le Lan</a>
                    <br>
                    Oxford
                </div>
              </td>
              <td><div class="col-xs-5"></div></td>
              <td style="vertical-align:middle">
                <div class="bio">
                    Charline Le Lan is a PhD student at the University of Oxford supervised by Yee Whye Teh and Shimon Whiteson. She is interested in unsupervised and reinforcement learning, often with an aim to build algorithms that learn and adapt knowledge representation for better generalization. Before that, she studied Statistics at Imperial College London and Mathematics at Ecole Centrale Paris.
                </div>
              </td>
            </tr>

            <tr>
              <td style="vertical-align:middle">
                <div class="col-xs-12">
                    <p align="center">
                    <img class="people-pic" src="../assets/img/invited/yingzhen.jpg" target="_blank">
                    </p>
                </div>
                <div class="people-name text-center">
                    <a href="http://yingzhenli.net/home/en/" target="_blank">Yingzhen Li</a>
                    <br>
                    ICL
                </div>
              </td>
              <td><div class="col-xs-5"></div></td>
              <td style="vertical-align:middle">
                <div class="bio">
                    Yingzhen Li is a Lecturer (equiv. US assistant professor) in Machine Learning at the Department of Computing, Imperial College London, UK. Before that she was a senior researcher at Microsoft Research Cambridge, and previously she has interned at Disney Research. She received her PhD in engineering from the University of Cambridge, UK. Yingzhen is passionate about building reliable machine learning systems, and her approach combines both Bayesian statistics and deep learning. She has worked extensively on approximate inference methods with applications to Bayesian deep learning and deep generative models, and her work has been applied in industrial systems and implemented in deep learning frameworks (e.g. Tensorflow Probability and Pyro). She gave an invited tutorial on Advances in Approximate Inference at NeurIPS 2020. She was a co-organiser of the Advances in Approximate Bayesian Inference (AABI) symposium in 2020/2021, NeurIPS 2020 Bayesian Deep Learning meet-up, and ICLR 2021 workshop on Neural Compression.
                </div>
              </td>
            </tr>


            <tr>
              <td style="vertical-align:middle">
                <div class="col-xs-12">
                    <p align="center">
                    <img class="people-pic" src="../assets/img/invited/phiala.jpg" target="_blank">
                    </p>
                </div>
                <div class="people-name text-center">
                    <a href="https://physics.mit.edu/faculty/phiala-shanahan/" target="_blank">Phiala Shanahan</a>
                    <br>
                    MIT
                </div>
              </td>
              <td><div class="col-xs-5"></div></td>
              <td style="vertical-align:middle">
                <div class="bio">
                    Phiala Shanahan is an assistant professor in the Center for Theoretical Physics at the Massachusetts Institute of Technology. She obtained her BSc from the University of Adelaide in 2012 and her Ph.D., also from the University of Adelaide, in 2015. Before joining the MIT physics faculty in 2018, Prof. Shanahan was a Postdoctoral Associate at MIT and held a joint position as Assistant Professor at the College of William & Mary and Senior Staff Scientist at the Thomas Jefferson National Accelerator Facility. Prof. Shanahan's research develops understanding of the structure and interactions of hadrons and nuclei from the fundamental (quark and gluon) degrees of freedom encoded in the Standard Model of particle physics using analytic tools, high performance supercomputing, and novel algorithms.
                </div>
              </td>
            </tr>


            <tr>
              <td style="vertical-align:middle">
                <div class="col-xs-12">
                    <p align="center">
                    <img class="people-pic" src="../assets/img/invited/marcus.jpg" target="_blank">
                    </p>
                </div>
                <div class="people-name text-center">
                    <a href="https://mbrubake.github.io/" target="_blank">Marcus Brubaker</a>
                    <br>
                    York
                </div>
              </td>
              <td><div class="col-xs-5"></div></td>
              <td style="vertical-align:middle">
                <div class="bio">
                    Marcus Brubaker is an Assistant Professor at York University, a Faculty Affiliate of the Vector Institute and an Adjunct Professor at the University of Toronto.  From 2018-2020 he worked as Research Director of Borealis AI, a machine learning research lab founded by the Royal Bank of Canada.  He is an Associate Editor for IET Computer Vision and has frequently serves as an area chair for machine learning and computer vision conferences including ECCV 2018, WACV 2019, UAI 2019, AAAI 2021 and CVPR 2021. Previously he worked on problems in electron cryomicroscopy (cryo-EM), human motion estimation, autonomous driving and Monte Carlo methods.  His current research is focused on probabilistic generative models and he continues to explore methods in cryo-EM.
                </div>
              </td>
            </tr>


            <tr>
              <td style="vertical-align:middle">
                <div class="col-xs-12">
                    <p align="center">
                    <img class="people-pic" src="../assets/img/invited/stefano.jpg" target="_blank">
                    </p>
                </div>
                <div class="people-name text-center">
                    <a href="https://cs.stanford.edu/~ermon/" target="_blank">Stefano Ermon</a>
                    <br>
                    ICL
                </div>
              </td>
              <td><div class="col-xs-5"></div></td>
              <td style="vertical-align:middle">
                <div class="bio">
                    Stefano Ermon is an Assistant Professor of Computer Science in the CS Department at Stanford University, where he is affiliated with the Artificial Intelligence Laboratory, and a fellow of the Woods Institute for the Environment. His research is centered on techniques for probabilistic modeling of data and is motivated by applications in the emerging field of computational sustainability. He has won several awards, including four Best Paper Awards (AAAI, UAI and CP), a NSF Career Award, ONR and AFOSR Young Investigator Awards, a Sony Faculty Innovation Award, a Hellman Faculty Fellowship, Microsoft Research Fellowship, Sloan Fellowship, and the IJCAI Computers and Thought Award. Stefano earned his Ph.D. in Computer Science at Cornell University in 2015.
                </div>
              </td>
            </tr>


            <tr>
              <td style="vertical-align:middle">
                <div class="col-xs-12">
<!--                    <p align="center">-->
<!--                    <img class="people-pic" src="../assets/img/invited/yingzhen.jpg" target="_blank">-->
<!--                    </p>-->
                </div>
                <div class="people-name text-center">
                    <a href="https://mnick.github.io/" target="_blank">Maximilian Nickel</a>
                    <br>
                    Facebook
                </div>
              </td>
              <td><div class="col-xs-5"></div></td>
              <td style="vertical-align:middle">
                <div class="bio">
<!--                    Yingzhen Li is a Lecturer (equiv. US assistant professor) in Machine Learning at the Department of Computing, Imperial College London, UK. Before that she was a senior researcher at Microsoft Research Cambridge, and previously she has interned at Disney Research. She received her PhD in engineering from the University of Cambridge, UK. Yingzhen is passionate about building reliable machine learning systems, and her approach combines both Bayesian statistics and deep learning. She has worked extensively on approximate inference methods with applications to Bayesian deep learning and deep generative models, and her work has been applied in industrial systems and implemented in deep learning frameworks (e.g. Tensorflow Probability and Pyro). She gave an invited tutorial on Advances in Approximate Inference at NeurIPS 2020. She was a co-organiser of the Advances in Approximate Bayesian Inference (AABI) symposium in 2020/2021, NeurIPS 2020 Bayesian Deep Learning meet-up, and ICLR 2021 workshop on Neural Compression.-->
                  TBA
                </div>
              </td>
            </tr>


            <tr>
              <td style="vertical-align:middle">
                <div class="col-xs-12">
<!--                    <p align="center">-->
<!--                    <img class="people-pic" src="../assets/img/invited/yingzhen.jpg" target="_blank">-->
<!--                    </p>-->
                </div>
                <div class="people-name text-center">
                    <a href="https://openai.com/blog/authors/aditya/" target="_blank">Aditya Ramesh</a>
                    <br>
                    OpenAI
                </div>
              </td>
              <td><div class="col-xs-5"></div></td>
              <td style="vertical-align:middle">
                <div class="bio">
<!--                    Yingzhen Li is a Lecturer (equiv. US assistant professor) in Machine Learning at the Department of Computing, Imperial College London, UK. Before that she was a senior researcher at Microsoft Research Cambridge, and previously she has interned at Disney Research. She received her PhD in engineering from the University of Cambridge, UK. Yingzhen is passionate about building reliable machine learning systems, and her approach combines both Bayesian statistics and deep learning. She has worked extensively on approximate inference methods with applications to Bayesian deep learning and deep generative models, and her work has been applied in industrial systems and implemented in deep learning frameworks (e.g. Tensorflow Probability and Pyro). She gave an invited tutorial on Advances in Approximate Inference at NeurIPS 2020. She was a co-organiser of the Advances in Approximate Bayesian Inference (AABI) symposium in 2020/2021, NeurIPS 2020 Bayesian Deep Learning meet-up, and ICLR 2021 workshop on Neural Compression.-->
                  TBA
                </div>
              </td>
            </tr>


          </table>
          </div>



<!--            Stefano Ermon (Stanford) <br>-->
<!--            Charline Le Lan (Oxford) <br>-->
<!--            Maximilian Nickel (Facebook) <br>-->
<!--            Marcus Brubaker (York) <br>-->
<!--            Phiala Shanahan (MIT) <br>-->
<!--            Yingzhen Li (ICL) <br>-->
<!--            Aditya Ramesh (OpenAI) <br>-->





        </div>

        <footer>
          &nbsp;
        </footer>

      </div>
    </div>
  </div>

      <!-- JavaScript -->
      <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
      <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/js/bootstrap.min.js"></script>
      <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
      </script>
      <script type="text/javascript" src="../js/main.js"></script>
</body>

</html>
























